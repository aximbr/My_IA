{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import load_boston\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import boston_valuation as val\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Data\n",
    "\n",
    "\n",
    "[Source: Original research paper](https://deepblue.lib.umich.edu/bitstream/handle/2027.42/22636/0000186.pdf?sequence=1&isAllowed=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#boston_dataset = load_boston()\n",
    "boston_dataset = fetch_openml(name='boston', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(boston_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(boston_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston_dataset.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data points and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(boston_dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset.data.shape # chaining dot notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_dataset.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual prices in thousands (000s) \n",
    "boston_dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration with Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pandas dataframe\n",
    "data = pd.DataFrame(data=boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "\n",
    "# Add column with the price (target)\n",
    "data['PRICE'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head() # The top rows look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail() # Rows at bottom of dataframe look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count() # show us the number of row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data - check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(data).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Visualising Data - Histograms, Distributions and Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['PRICE'], bins=50, ec='black', color='#2196f3')\n",
    "plt.xlabel('Price in 000s')\n",
    "plt.ylabel('Nr. of Houses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "#sns.distplot(data['PRICE'], bins=50, hist=True, kde=False, color='#fbc02d')\n",
    "sns.displot(data['PRICE'], bins=50, kind='hist', kde=False, color='#fbc02d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['RM'], ec='black', color='#00796b')\n",
    "plt.xlabel('Average Number of Rooms')\n",
    "plt.ylabel('Nr. of Houses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RM'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Create a meaningful histogram for RAD using matplotlib ... in royal purple\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(data['RAD'], bins=24, ec='black', color='#7b1fa2', rwidth=0.5)\n",
    "plt.xlabel('Accessibility to Highways')\n",
    "plt.ylabel('Nr. of Houses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['RAD'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency = data['RAD'].value_counts()\n",
    "#type(frequency)\n",
    "#frequency.index\n",
    "#frequency.axes[0]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.xlabel('Accessibility to Highways')\n",
    "plt.ylabel('Nr. of Houses')\n",
    "plt.bar(frequency.index, height=frequency)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CHAS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PRICE'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PRICE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Correlation\n",
    "\n",
    "## $$ \\rho _{XY} = corr(X,Y)$$\n",
    "## $$ -1.0 \\leq \\rho _{XY} \\leq +1.0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PRICE'].corr(data['RM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Calculate the correlation between property prices and the pupil teacher ratio\n",
    "data['PRICE'].corr(data['PTRATIO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr() # Pearson Correlation Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros_like(data.corr())\n",
    "triangle_indices = np.triu_indices_from(mask)\n",
    "mask[triangle_indices] = True\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(data.corr(), mask=mask, annot=True, annot_kws={\"size\": 14})\n",
    "sns.set_style('white')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Challenge: Picture the relationship between pollution and distance in your head\n",
    "# Then create a scatter plot between DIS and NOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nox_dis_corr = round(data['NOX'].corr(data['DIS']), 3)\n",
    "\n",
    "plt.figure(figsize=(9, 6), dpi=300)\n",
    "plt.scatter(x=data['DIS'], y=data['NOX'], alpha=0.6, s=80, color='indigo')\n",
    "\n",
    "plt.title(f'DIS vs NOX (Correlation {nox_dis_corr})', fontsize=14)\n",
    "plt.xlabel('DIS - Distance from employment', fontsize=14)\n",
    "plt.ylabel('NOX - Nitric Oxide Pollution', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "sns.jointplot(x=data['DIS'], y=data['NOX'], size=7, color='indigo', joint_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "#sns.jointplot(x=data['DIS'], y=data['NOX'], kind='hex', size=7, color='blue')\n",
    "sns.jointplot(x=data['DIS'], y=data['NOX'], kind='hex', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "#sns.jointplot(x=data['TAX'], y=data['RAD'], size=7, color='darkred', joint_kws={'alpha':0.5})\n",
    "sns.jointplot(x=data['TAX'], y=data['RAD'], color='darkred', joint_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.lmplot(x='TAX', y='RAD', data=data, size=7)\n",
    "sns.lmplot(x='TAX', y='RAD', data=data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Challenge: Create a scatter plot between the house prices and the number of rooms (RM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_tgt_corr = round(data['RM'].corr(data['PRICE']), 3)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(x=data['RM'], y=data['PRICE'], alpha=0.6, s=80, color='skyblue')\n",
    "\n",
    "plt.title(f'RM vs PRICE (Correlation {rm_tgt_corr})', fontsize=14)\n",
    "plt.xlabel('RM - Median nr of rooms', fontsize=14)\n",
    "plt.ylabel('PRICE - property price in 000s', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='RM', y='PRICE', data=data, size=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sns.pairplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sns.pairplot(data, kind='reg', plot_kws={'line_kws':{'color': 'cyan'}})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training & Test Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = data['PRICE']\n",
    "features = data.drop('PRICE', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, \n",
    "                                                    test_size=0.2, random_state=10)\n",
    "\n",
    "# % of training set\n",
    "len(X_train)/len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of test data set\n",
    "X_test.shape[0]/features.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariable Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "#Challenge: print out r-squared for training and test datasets\n",
    "print('Training data r-squared:', regr.score(X_train, y_train))\n",
    "print('Test data r-squared:', regr.score(X_test, y_test))\n",
    "\n",
    "print('Intercept', regr.intercept_)\n",
    "pd.DataFrame(data=regr.coef_, index=X_train.columns, columns=['coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PRICE'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log = np.log(data['PRICE'])\n",
    "y_log.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_log.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_log)\n",
    "plt.title(f'Log price with skew {y_log.skew()}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='LSTAT', y='PRICE', data=data, size=7, \n",
    "           scatter_kws={'alpha': 0.6}, line_kws={'color':'darkred'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = features\n",
    "transformed_data['LOG_PRICE'] = y_log\n",
    "\n",
    "sns.lmplot(x='LSTAT', y='LOG_PRICE', data=transformed_data, size=7, \n",
    "           scatter_kws={'alpha': 0.6}, line_kws={'color':'cyan'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression using log prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.log(data['PRICE']) # Use log prices\n",
    "features = data.drop('PRICE', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, \n",
    "                                                    test_size=0.2, random_state=10)\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "print('Training data r-squared:', regr.score(X_train, y_train))\n",
    "print('Test data r-squared:', regr.score(X_test, y_test))\n",
    "\n",
    "print('Intercept', regr.intercept_)\n",
    "pd.DataFrame(data=regr.coef_, index=X_train.columns, columns=['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charles River Property Premium\n",
    "np.e**0.080475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p values & Evaluating Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_incl_const = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "#results.params\n",
    "#results.pvalues\n",
    "\n",
    "pd.DataFrame({'coef': results.params, 'p-value': round(results.pvalues, 3)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing for Multicollinearity\n",
    "\n",
    "$$ TAX = \\alpha _0 + \\alpha _1 RM + \\alpha _2 NOX + ... + \\alpha _{12}LSTAT $$\n",
    "\n",
    "$$ VIF _{TAX} = \\frac{1}{(1 - R _{TAX} ^ 2)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_inflation_factor(exog=X_incl_const.values, exog_idx=1)\n",
    "#type(X_incl_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: print out the number of columns in X_incl_const\n",
    "len(X_incl_const.columns)\n",
    "X_incl_const.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: write a for loop that prints out all the VIFs for all the features\n",
    "for i in range(X_incl_const.shape[1]):\n",
    "    print(variance_inflation_factor(exog=X_incl_const.values, exog_idx=i))\n",
    "print('All done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = [] # empty list\n",
    "for i in range(X_incl_const.shape[1]):\n",
    "    vif.append(variance_inflation_factor(exog=X_incl_const.values, exog_idx=i))\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = [variance_inflation_factor(exog=X_incl_const.values, \n",
    "                                 exog_idx=i) for i in range(X_incl_const.shape[1])]\n",
    "\n",
    "pd.DataFrame({'coef_name': X_incl_const.columns, \n",
    "             'vif': np.around(vif, 2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Simplification & the BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model with log prices and all features\n",
    "\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "org_coef = pd.DataFrame({'coef': results.params, 'p-value': round(results.pvalues, 3)})\n",
    "\n",
    "# Challenge: find and check official docs for results object and print out BIC & r-squared\n",
    "print('BIC is', results.bic)\n",
    "print('r-squared is', results.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced model #1 excluding INDUS\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "X_incl_const = X_incl_const.drop(['INDUS'], axis=1)\n",
    "\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "coef_minus_indus = pd.DataFrame({'coef': results.params, 'p-value': round(results.pvalues, 3)})\n",
    "\n",
    "print('BIC is', results.bic)\n",
    "print('r-squared is', results.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced model #2 excluding INDUS and AGE\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "X_incl_const = X_incl_const.drop(['INDUS', 'AGE'], axis=1)\n",
    "\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "reduced_coef = pd.DataFrame({'coef': results.params, 'p-value': round(results.pvalues, 3)})\n",
    "\n",
    "print('BIC is', results.bic)\n",
    "print('r-squared is', results.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [org_coef, coef_minus_indus, reduced_coef]\n",
    "pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Residuals & Residual Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified model: transformed (using log prices) & simplified (dropping two features)\n",
    "prices = np.log(data['PRICE']) # Use log prices\n",
    "features = data.drop(['PRICE', 'INDUS', 'AGE'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, \n",
    "                                                    test_size=0.2, random_state=10)\n",
    "\n",
    "# Using Statsmodel\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "# Residuals\n",
    "# residuals = y_train - results.fittedvalues\n",
    "# results.resid\n",
    "\n",
    "# Graph of Actual vs. Predicted Prices\n",
    "corr = round(y_train.corr(results.fittedvalues), 2)\n",
    "plt.scatter(x=y_train, y=results.fittedvalues, c='navy', alpha=0.6)\n",
    "plt.plot(y_train, y_train, color='cyan')\n",
    "\n",
    "plt.xlabel('Actual log prices $y _i$', fontsize=14)\n",
    "plt.ylabel('Prediced log prices $\\hat y _i$', fontsize=14)\n",
    "plt.title(f'Actual vs Predicted log prices: $y _i$ vs $\\hat y_i$ (Corr {corr})', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(x=np.e**y_train, y=np.e**results.fittedvalues, c='blue', alpha=0.6)\n",
    "plt.plot(np.e**y_train, np.e**y_train, color='cyan')\n",
    "\n",
    "plt.xlabel('Actual prices 000s $y _i$', fontsize=14)\n",
    "plt.ylabel('Prediced prices 000s $\\hat y _i$', fontsize=14)\n",
    "plt.title(f'Actual vs Predicted prices: $y _i$ vs $\\hat y_i$ (Corr {corr})', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs Predicted values\n",
    "\n",
    "plt.scatter(x=results.fittedvalues, y=results.resid, c='navy', alpha=0.6)\n",
    "\n",
    "plt.xlabel('Predicted log prices $\\hat y _i$', fontsize=14)\n",
    "plt.ylabel('Residuals', fontsize=14)\n",
    "plt.title('Residuals vs Fitted Values', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Mean Squared Error & R-Squared\n",
    "reduced_log_mse = round(results.mse_resid, 3)\n",
    "reduced_log_rsquared = round(results.rsquared, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Residuals (log prices) - checking for normality\n",
    "resid_mean = round(results.resid.mean(), 3)\n",
    "resid_skew = round(results.resid.skew(), 3)\n",
    "\n",
    "sns.distplot(results.resid, color='navy')\n",
    "plt.title(f'Log price model: residuals Skew ({resid_skew}) Mean ({resid_mean})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Challenge: Using the original model with all the features and normal prices generate:\n",
    "# Plot of actual vs predicted prices (incl. correlation) using a different colour\n",
    "# Plot of residuals vs. predicted prices\n",
    "# Plot of distribution of residuals (incl. skew)\n",
    "# Analyse the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model: normal prices & all features\n",
    "prices = data['PRICE']\n",
    "features = data.drop(['PRICE'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, \n",
    "                                                    test_size=0.2, random_state=10)\n",
    "\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "# Graph of Actual vs. Predicted Prices\n",
    "corr = round(y_train.corr(results.fittedvalues), 2)\n",
    "plt.scatter(x=y_train, y=results.fittedvalues, c='indigo', alpha=0.6)\n",
    "plt.plot(y_train, y_train, color='cyan')\n",
    "\n",
    "plt.xlabel('Actual prices 000s $y _i$', fontsize=14)\n",
    "plt.ylabel('Prediced prices 000s $\\hat y _i$', fontsize=14)\n",
    "plt.title(f'Actual vs Predicted prices: $y _i$ vs $\\hat y_i$ (Corr {corr})', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs Predicted values\n",
    "plt.scatter(x=results.fittedvalues, y=results.resid, c='indigo', alpha=0.6)\n",
    "\n",
    "plt.xlabel('Predicted prices $\\hat y _i$', fontsize=14)\n",
    "plt.ylabel('Residuals', fontsize=14)\n",
    "plt.title('Residuals vs Fitted Values', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Residual Distribution Chart\n",
    "resid_mean = round(results.resid.mean(), 3)\n",
    "resid_skew = round(results.resid.skew(), 3)\n",
    "\n",
    "sns.distplot(results.resid, color='indigo')\n",
    "plt.title(f'Residuals Skew ({resid_skew}) Mean ({resid_mean})')\n",
    "plt.show()\n",
    "\n",
    "# Mean Squared Error & R-Squared\n",
    "full_normal_mse = round(results.mse_resid, 3)\n",
    "full_normal_rsquared = round(results.rsquared, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Omitting Key Features using log prices\n",
    "prices = np.log(data['PRICE'])\n",
    "features = data.drop(['PRICE', 'INDUS', 'AGE', 'LSTAT', 'RM', 'NOX', 'CRIM'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, prices, \n",
    "                                                    test_size=0.2, random_state=10)\n",
    "\n",
    "X_incl_const = sm.add_constant(X_train)\n",
    "model = sm.OLS(y_train, X_incl_const)\n",
    "results = model.fit()\n",
    "\n",
    "# Graph of Actual vs. Predicted Prices\n",
    "corr = round(y_train.corr(results.fittedvalues), 2)\n",
    "plt.scatter(x=y_train, y=results.fittedvalues, c='#e74c3c', alpha=0.6)\n",
    "plt.plot(y_train, y_train, color='cyan')\n",
    "\n",
    "plt.xlabel('Actual log prices $y _i$', fontsize=14)\n",
    "plt.ylabel('Predicted log prices $\\hat y _i$', fontsize=14)\n",
    "plt.title(f'Actual vs Predicted prices with omitted variables: $y _i$ vs $\\hat y_i$ (Corr {corr})', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs Predicted values\n",
    "plt.scatter(x=results.fittedvalues, y=results.resid, c='#e74c3c', alpha=0.6)\n",
    "\n",
    "plt.xlabel('Predicted prices $\\hat y _i$', fontsize=14)\n",
    "plt.ylabel('Residuals', fontsize=14)\n",
    "plt.title('Residuals vs Fitted Values', fontsize=17)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Mean Squared Error & R-Squared\n",
    "omitted_var_mse = round(results.mse_resid, 3)\n",
    "omitted_var_rsquared = round(results.rsquared, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'R-Squared': [reduced_log_rsquared, full_normal_rsquared, omitted_var_rsquared],\n",
    "             'MSE': [reduced_log_mse, full_normal_mse, omitted_var_mse], \n",
    "             'RMSE': np.sqrt([reduced_log_mse, full_normal_mse, omitted_var_mse])}, \n",
    "            index=['Reduced Log Model', 'Full Normal Price Model', 'Omitted Var Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Our estimate for a house price is $30,000. Calculate the upper and lower bound\n",
    "# for a 95% prediction interval using the reduced log model\n",
    "\n",
    "print('1 s.d. in log prices is', np.sqrt(reduced_log_mse))\n",
    "print('2 s.d. in log prices is', 2*np.sqrt(reduced_log_mse))\n",
    "\n",
    "upper_bound = np.log(30) + 2*np.sqrt(reduced_log_mse)\n",
    "print('The upper bound in log prices for a 95% prediction interval is ', upper_bound)\n",
    "print('The upper bound in normal prices is $', np.e**upper_bound * 1000)\n",
    "\n",
    "lower_bound = np.log(30) - 2*np.sqrt(reduced_log_mse)\n",
    "print('The lower bound in log prices for a 95% prediction interval is ', lower_bound)\n",
    "print('The lower bound in normal prices is $', np.e**lower_bound * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "30000 + np.e**(2*np.sqrt(reduced_log_mse)) * 1000 # Wrong! Add first. Transform afterwards. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.get_dollar_estimate(8, 15, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
